{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "268ab07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4447083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_extract_h1(Url):\n",
    "        # Make a request to the webpage\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "        page = requests.get(URL, headers=headers)\n",
    "        soup=BeautifulSoup(page.content, 'html.parser')\n",
    "        #extract title from the article\n",
    "        title=soup.find('h1', class_=[\"entry-title\", \"tdb-title-text\"])\n",
    "        title=title.text.replace('\\n',\" \")\n",
    "#         title = soup.find('title').text\n",
    "        return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418c7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def title_extract_h3(Url):\n",
    "#         # Make a request to the webpage\n",
    "#         headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "#         page = requests.get(URL, headers=headers)\n",
    "#         soup=BeautifulSoup(page.content, 'html.parser')\n",
    "#         #extract title from the article\n",
    "#         title=soup.find('h3',class_=\"entry-title\")\n",
    "#         title=title.text.replace('\\n',\" \")\n",
    "#         return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73946470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error extracting title from https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/: 'NoneType' object has no attribute 'text'\n",
      "Error extracting title from https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/: 'NoneType' object has no attribute 'text'\n",
      "Error extracting title from https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/: HTTPSConnectionPool(host='insights.blackcoffer.com', port=443): Max retries exceeded with url: /deep-learning-impact-on-areas-of-e-learning/ (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001AEBC900400>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))\n",
      "Error extracting title from https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/: 'NoneType' object has no attribute 'text'\n",
      "Error extracting title from https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/: 'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "data = pd.read_excel('Input.xlsx')\n",
    "article_titles = []\n",
    "# Iterate over each row and extract the article text\n",
    "for index, row in data.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    URL = row['URL']\n",
    "    try:\n",
    "        title = title_extract(URL)\n",
    "        article_titles.append(title)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting title from {URL}: {str(e)}\")\n",
    "print (*article_titles, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8eea525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract(URL):\n",
    "    try:\n",
    "        # Make a request to the webpage\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "        page = requests.get(URL, headers=headers)\n",
    "        soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        # Check the response status code\n",
    "        if page.status_code == 200:\n",
    "            # Webpage exists, continue with scraping\n",
    "            content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "            content=content[0].text.replace('\\n',\" \")\n",
    "            file_name = f'{url_id}.txt'\n",
    "            \n",
    "            # Save the article text to a text file\n",
    "            with open(file_name, 'w', encoding=\"utf8\") as file:\n",
    "                file.write(content)\n",
    "\n",
    "            print(f'Saved article {file_name}')\n",
    "            pass\n",
    "        \n",
    "        elif page.status_code == 404:\n",
    "            # Webpage does not exist\n",
    "            print(\"Page not found!\")\n",
    "        \n",
    "        else:\n",
    "            # Handle other response status codes if needed\n",
    "            print(\"Unexpected response:\", response.status_code)\n",
    "            print(f'Saved article {file_name}')\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle any other request-related exceptions\n",
    "        print(\"Error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "data = pd.read_excel('Input.xlsx')\n",
    "article_dict = {}\n",
    "# Iterate over each row and extract the article text\n",
    "for index, row in data.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    URL = row['URL']\n",
    "    text_extract(URL)\n",
    "    article_dict.update({url_id:URL})\n",
    "print('Extraction complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21854efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acf67adb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(page\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m title\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry-title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m title\u001b[38;5;241m=\u001b[39m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m title\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "url=\"\"\"https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "title=soup.find('h1',class_=\"entry-title\")\n",
    "title=title.text.replace('\\n',\" \")\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "607e8a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Introduction “If anything kills over 10 million people in the next few decades it will be a highly infectious virus rather than a war Not missiles but microbes” Bill Gates’s remarks at a TED conference in 2014 right after the world had avoided the Ebola outbreak When the new unprecedented invisible virus hit us it met an overwhelmed and unprepared healthcare system and oblivious population This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities For the past few years artificial intelligence has proven to be of tangible potential in the healthcare sectors clinical practices translational medical and biomedical research After the first case was detected in China on December 31st 2019 it was an AI program developed by BlueDot that alerted the world about the pandemic It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of crossinfection by using AI algorithms that can track patterns and extract some features to classify or categorise them So how does AI do that IBM Watson a sophisticated AI that works on cloud computing and natural language processing has prominently contributed to the healthcare sector on a global level Being a conversational AI since 2013 Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs  Researchers at Google Inc showed that an AI system can be trained on thousands of images to achieve physicianlevel sensitivity By identifying the molecular patterns associated with disease status and its subtypes gene expression and protein abundance levels machine learning methods can detect fatal diseases like cancer at an early stage Machine Learning ML techniques focus mainly on analyzing structured data which can further help in clustering patients’ traits and infer the probability of disease outcomes Since patient traits mainly include masses of data relating to age gender disease history diseasespecific data like diagnostic imaging and gene expressions etc ML can extract features from these data inputs by constructing data analytical algorithms ML algorithms are either supervised or unsupervised Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters Since patient traits are recorded in multiple dimensions such as genes principal component analysisPCA creates the apparatus to reduce these dimensions which humans could have not done alone Supervised learning considers the outcomes of the subjects together with the traits and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event expected value of a disease level or expected survival time or risk of Down’s syndrome Biomarker panels that are mostly used to detect ovarian cancer have outperformed the conventional statistical methods due to machine learning In addition to this the use of EHRs and Bayesian networks which are a part of supervised machine learning algorithms can predict clinical outcomes and mortality respectively Unstructured data such as clinical notes and texts are converted into machinereadable structured data with the help of natural language processingNLP NLP works with two components text processing and classification Text processing helps in identifying a series of diseaserelevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients Healthcare organizations use NLPbased chatbots to increase interactions with patients keeping their mental health and wellness in check Deep learning is a modern extension of the classical neural network techniques which helps explore more complex nonlinear patterns in data using algorithms like convolution neural network recurrent neural network deep belief network and deep neural network which enables more accurate clinical prediction When it comes to genome interpretation deep neural networks surpass the conventional methods of logistics regression and support vector machines Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis Another method known as the Learningbased Optimization of the Under Sampling Pattern LOUPE is based on integrating full resolution MRI scans with the convolutional neural network algorithm which helps in creating more accurate reconstructions Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery Even after striking the right balance between human decisions and AI precision robotic surgery reduces surgeon efficiency as they have to be manually operated through a console Thus autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs cut tissues etc or robotic catheters that can navigate whether it is touching blood tissue or valve Researchers at Children’s National Hospital Washington have already developed an AI called Smart Tissue Autonomous Robot STAR which performs a colon anastomosis on its own with the help of an MLpowered suturing tool that automatically detects the patient’s breathing pattern to apply suture at the correct point An image of STAR during surgery Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information medications and therapies How can It help in Biomedical research Since AI can analyze literature beyond readability it can be used to concise biomedical research With the help of ML algorithms and NLP AI can accelerate screening and indexing of biomedical research by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly Taking it to the next level AI systems like the computational modelling assistant CMA helps researchers to construct simulation models from the concepts they have in mind Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and proteinprotein interaction information extraction AI as precision medicine Since precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile the various AI devices pave the way to practice it more efficiently With the help of ML complex algorithms like large datasets can be used to predict and create an optimal treatment strategy Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state food intake or health monitoring\\xa0 “Omics” refers to the collective technologies that help in exploring the roles relationships of various branches ending with the suffix “omics” such as genomics proteomics etc Omicsbased tests based on machine learning algorithms help find correlations and predict treatment responses ultimately creating personalized treatments for individual patients\\xa0 How it helps in psychology and neuro patients For psychologists studying creativity\\xa0 AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon Studies show that \\xa0AI can conduct therapy sessions etherapy sessions and assessments autonomously also assisting human practitioners before during or after sessions The Detection and Computational Analysis of Psychological Signal project uses ML computer vision and NLP to analyze language physical gestures and social signals to identify cues for human distress This groundbreaking technology assesses soldiers returning from combat and recognizes those who require further mental health support In the future it will combine data captured during facetoface interviews with information on sleeping eating and online behaviours for a complete patient view Stroke identification Stroke is another frequently occurring disease that affects more than 500 million people worldwide Thrombus\\xa0 in the vessel cerebral infarction is the major about 85 cause of stroke occurrence In recent years AI techniques have been used in numerous strokerelated studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem With AI at our disposal large amounts of data with rich information more complications and reallife clinical questions can be addressed in this arena Currently two ML algorithms genetic fuzzy finite state machine and PCA were implemented to build a model building solution These include a human activity recognition stage and a stroke onset detection stage An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis Patient Monitoring Today the market for AIbased patient monitoring is impressive and monetarily enticing It is evolving with artificial sensors smart technologies and explores everything from braincomputer interfaces to nanorobotics Companies with their smartwatches have engaged people to perform remote monitoring even when they are not “patients” An obvious place to start is with wearable and embedded sensors glucose monitors pulse monitors oximeters and ECG monitors With patient monitoring becoming crucial AI finds numerous applications in chronic conditions intensive care units operating rooms emergency rooms and cardiac wards where timeless clinical decisionmaking can be measured in seconds More advances have started to gain traction like smart prosthetics and implants These play an impeccable role in patient management postsurgery or rehabilitation Demographics laboratory results and vital signs can also be used to predict cardiac arrest transfer into the intensive care unit or even death In addition an interpretable machinelearning model can assist anesthesiologists in predicting hypoxaemia events during surgery This suggests that with deeplearning algorithms raw patientmonitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decisionmaking  \\xa0Conclusion Considering the vast range of tasks that an AI can do it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels Using sophisticated algorithms AI can bring a revolution in the healthcare sector Even after facing challenges like whether the technology will be able to deliver the promises ethical measures training physicians to use it standard regulations etc the role of AI in transforming the clinical practices cannot be ignored The biggest challenge is the integration of AI in daily practice All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective Blackcoffer Insights 29 Sanskriti Sunderum and Aayushi Nauhwar SRCC Delhi University '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = content.translate(str.maketrans('', '', string.punctuation)) \n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96fceab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Swati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Swati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', '“', 'If', 'anything', 'kills', 'over', '10', 'million', 'people', 'in', 'the', 'next', 'few', 'decades', 'it', 'will', 'be', 'a', 'highly', 'infectious', 'virus', 'rather', 'than', 'a', 'war', 'Not', 'missiles', 'but', 'microbes', '”', 'Bill', 'Gates', '’', 's', 'remarks', 'at', 'a', 'TED', 'conference', 'in', '2014', 'right', 'after', 'the', 'world', 'had', 'avoided', 'the', 'Ebola', 'outbreak']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "text_tokens = word_tokenize(content)\n",
    "print(text_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "166197b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4705287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Introduction', '“', 'If', 'anything', 'kills', '10', 'million', 'people', 'next', 'decades', 'highly', 'infectious', 'virus', 'rather', 'war', 'Not', 'missiles', 'microbes', '”', 'Bill', 'Gates', '’', 'remarks', 'TED', 'conference', '2014', 'right', 'world', 'avoided', 'Ebola', 'outbreak', 'When', 'new', 'unprecedented', 'invisible', 'virus', 'hit', 'us', 'met', 'overwhelmed']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "my_stop_words = stopwords.words('english')\n",
    "my_stop_words.append('the')\n",
    "no_stop_tokens = [word for word in text_tokens if not word in my_stop_words]\n",
    "print(no_stop_tokens[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d58a496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_stop_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef9468ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article 37.txt\n",
      "Saved article 38.txt\n",
      "Saved article 39.txt\n",
      "Saved article 40.txt\n",
      "Saved article 41.txt\n",
      "Saved article 42.txt\n",
      "Saved article 43.txt\n",
      "Saved article 44.txt\n",
      "Saved article 45.txt\n",
      "Saved article 46.txt\n",
      "Saved article 47.txt\n",
      "Saved article 48.txt\n",
      "Saved article 49.txt\n",
      "Saved article 50.txt\n",
      "Saved article 51.txt\n",
      "Saved article 52.txt\n",
      "Saved article 53.txt\n",
      "Saved article 54.txt\n",
      "Saved article 55.txt\n",
      "Saved article 56.txt\n",
      "Saved article 57.txt\n",
      "Saved article 58.txt\n",
      "Saved article 59.txt\n",
      "Saved article 60.txt\n",
      "Saved article 61.txt\n",
      "Saved article 62.txt\n",
      "Saved article 63.txt\n",
      "Saved article 64.txt\n",
      "Saved article 65.txt\n",
      "Saved article 66.txt\n",
      "Saved article 67.txt\n",
      "Saved article 68.txt\n",
      "Saved article 69.txt\n",
      "Saved article 70.txt\n",
      "Saved article 71.txt\n",
      "Saved article 72.txt\n",
      "Saved article 73.txt\n",
      "Saved article 74.txt\n",
      "Saved article 75.txt\n",
      "Saved article 76.txt\n",
      "Saved article 77.txt\n",
      "Saved article 78.txt\n",
      "Saved article 79.txt\n",
      "Saved article 80.txt\n",
      "Saved article 81.txt\n",
      "Saved article 82.txt\n",
      "Saved article 83.txt\n",
      "Saved article 84.txt\n",
      "Saved article 85.txt\n",
      "Saved article 86.txt\n",
      "Saved article 87.txt\n",
      "Saved article 88.txt\n",
      "Saved article 89.txt\n",
      "Saved article 90.txt\n",
      "Saved article 91.txt\n",
      "Saved article 92.txt\n",
      "Saved article 93.txt\n",
      "Saved article 94.txt\n",
      "Saved article 95.txt\n",
      "Saved article 96.txt\n",
      "Saved article 97.txt\n",
      "Saved article 98.txt\n",
      "Saved article 99.txt\n",
      "Saved article 100.txt\n",
      "Saved article 101.txt\n",
      "Saved article 102.txt\n",
      "Saved article 103.txt\n",
      "Saved article 104.txt\n",
      "Saved article 105.txt\n",
      "Saved article 106.txt\n",
      "Saved article 107.txt\n",
      "Saved article 108.txt\n",
      "Saved article 109.txt\n",
      "Saved article 110.txt\n",
      "Saved article 111.txt\n",
      "Saved article 112.txt\n",
      "Saved article 113.txt\n",
      "Saved article 114.txt\n",
      "Saved article 115.txt\n",
      "Saved article 116.txt\n",
      "Saved article 117.txt\n",
      "Saved article 118.txt\n",
      "Saved article 119.txt\n",
      "Saved article 120.txt\n",
      "Saved article 121.txt\n",
      "Saved article 122.txt\n",
      "Saved article 123.txt\n",
      "Saved article 124.txt\n",
      "Saved article 125.txt\n",
      "Saved article 126.txt\n",
      "Saved article 127.txt\n",
      "Saved article 128.txt\n",
      "Saved article 129.txt\n",
      "Saved article 130.txt\n",
      "Saved article 131.txt\n",
      "Saved article 132.txt\n",
      "Saved article 133.txt\n",
      "Saved article 134.txt\n",
      "Saved article 135.txt\n",
      "Saved article 136.txt\n",
      "Saved article 137.txt\n",
      "Saved article 138.txt\n",
      "Saved article 139.txt\n",
      "Saved article 140.txt\n",
      "Saved article 141.txt\n",
      "Saved article 142.txt\n",
      "Saved article 143.txt\n",
      "Saved article 144.txt\n",
      "Saved article 145.txt\n",
      "Saved article 146.txt\n",
      "Saved article 147.txt\n",
      "Saved article 148.txt\n",
      "Saved article 149.txt\n",
      "Saved article 150.txt\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f39b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Make a request to the webpage\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0\"}\n",
    "    page = requests.get(URL, headers=headers)\n",
    "    soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    title=soup.find('h3',class_=\"entry-title\")\n",
    "    title=title.text.replace('\\n',\" \")\n",
    "    # Check the response status code\n",
    "    if response.status_code == 200:\n",
    "        # Webpage exists, continue with scraping\n",
    "        content=soup.findAll(attrs={'class':'td-post-content'})\n",
    "        content=content[0].text.replace('\\n',\" \")\n",
    "\n",
    "        file_name = f'{url_id}.txt'\n",
    "        # Save the article text to a text file\n",
    "        with open(file_name, 'w', encoding=\"utf8\") as file:\n",
    "            file.write(content)\n",
    "\n",
    "        print(f'Saved article {file_name}')\n",
    "        pass\n",
    "    elif response.status_code == 404:\n",
    "        # Webpage does not exist\n",
    "        print(\"Page not found!\")\n",
    "    else:\n",
    "        # Handle other response status codes if needed\n",
    "        print(\"Unexpected response:\", response.status_code)\n",
    "        print(f'Saved article {file_name}')\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # Handle any other request-related exceptions\n",
    "    print(\"Error occurred:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
